{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01ca31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import math\n",
    "import itertools\n",
    "import copy\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0227e16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device config\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Random seed\n",
    "seed = 2022\n",
    "torch.random.manual_seed(seed)\n",
    "np.random.seed(2022)\n",
    "\n",
    "# Tensorboard writer\n",
    "writer = SummaryWriter(\"runs/multilabelsclass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54d211b",
   "metadata": {},
   "source": [
    "# Data Pre-Processing and contruct CNN structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f88aed8",
   "metadata": {},
   "source": [
    "# 1. Read Image & Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a1914f",
   "metadata": {},
   "source": [
    "### 1.1 Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25890e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory\n",
    "data_dir = '../pascal_2007'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.mkdir(data_dir)\n",
    "    \n",
    "# Save directory\n",
    "save_dir = './saved'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "# Image directory\n",
    "train_img_dir = os.path.join(data_dir, 'train')\n",
    "test_img_dir = os.path.join(data_dir, 'test')\n",
    "\n",
    "# Annotaion file\n",
    "train_anno_file = os.path.join(data_dir, 'train.csv')\n",
    "test_anno_file = os.path.join(data_dir, 'test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146b4ee9",
   "metadata": {},
   "source": [
    "### 1.2 Train/Val/Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e2143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = pd.read_csv(train_anno_file)\n",
    "\n",
    "train_image_label_value = (train_label[\"is_valid\"].values)\n",
    "valid_image_label_value = (train_label[\"is_valid\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d10f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all index of training image\n",
    "train_image_label_index = [i for i, x in enumerate(train_image_label_value) if x]\n",
    "valid_image_label_index = [i for i, x in enumerate(valid_image_label_value) if not x]\n",
    "print(\"Number of training image: \", len(train_image_label_index))\n",
    "print(\"Number of valid image: \", len(valid_image_label_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844a6fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_image_label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a124b563",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get all image file\n",
    "image_file_name = train_label[\"fname\"].values\n",
    "image_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f470678d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all image\n",
    "total_train_image = [] \n",
    "for image in image_file_name:\n",
    "    image = plt.imread(os.path.join(train_img_dir, image))\n",
    "    total_train_image.append(image)\n",
    "\n",
    "len(total_train_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c759b8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image = [ total_train_image[i] for i in train_image_label_index]\n",
    "val_image = [ total_train_image[i] for i in valid_image_label_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfad48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(total_train_image[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397fe2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read all label for train and val data\n",
    "\n",
    "labels = train_label[\"labels\"].values\n",
    "\n",
    "training_labels = labels[train_image_label_index]\n",
    "validation_labels = labels[valid_image_label_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49d9900",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eafbc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get all image file\n",
    "test_label = pd.read_csv(test_anno_file)\n",
    "test_image_file_name = test_label[\"fname\"].values\n",
    "test_image_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026559ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test data\n",
    "\n",
    "total_test_image = [] \n",
    "for image in test_image_file_name:\n",
    "    image = plt.imread(os.path.join(test_img_dir, image))\n",
    "    total_test_image.append(image)\n",
    "\n",
    "test_anno_label = pd.read_csv(test_anno_file)\n",
    "test_labels = test_anno_label[\"labels\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c334a2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(total_test_image[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09eb140",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c99f988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label_to_array(labels):\n",
    "    for ind, label in enumerate(labels):\n",
    "        labels[ind] = label.split(\" \")\n",
    "    return labels        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87253d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels = convert_label_to_array(training_labels)\n",
    "validation_labels = convert_label_to_array(validation_labels)\n",
    "test_labels = convert_label_to_array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e065efd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2990df43",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ecdf63",
   "metadata": {},
   "source": [
    "### 1.3 Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902f5d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all labels\n",
    "labels = []\n",
    "\n",
    "for label in training_labels:\n",
    "    labels = labels + label\n",
    "    \n",
    "labels = sorted(list(set(labels)))\n",
    "\n",
    "print('Number of labels: ', len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfe80f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d33e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create custom dataset:\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    # __init_function run once when instantiating the Dataset object\n",
    "    def __init__(self, annotations, images, labellist, transforms=None):\n",
    "        super().__init__()\n",
    "        self.img = images\n",
    "        self.annotations = annotations    \n",
    "        self.labellist = labellist\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    # __len__ func return the num of samples in dataset \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    # Load and return a sample from the dataset at the given index `idx` then convert it to tensor \n",
    "    # retrieves the corresponding labels from the csv data, call the transform function on them (if applicable)\n",
    "    # then return the tensor image and corresponding label.\n",
    "    \n",
    "    # convert label of and sample to index of these label in the labellist\n",
    "    def text_to_index(self, labellist, annotations):\n",
    "        index = []\n",
    "        for item in annotations:\n",
    "            index.append(self.labellist.index(item))\n",
    "        return index\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # convert image to tensor and transform image\n",
    "        image = self.img[idx]\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "            \n",
    "        # convert label to one hot encoding\n",
    "        labels_index = self.text_to_index(self.labellist, self.annotations[idx])\n",
    "        labels_index = torch.tensor(labels_index)\n",
    "        labels_onehot = F.one_hot(labels_index, num_classes=len(self.labellist))\n",
    "        onehot_label = labels_onehot.sum(dim=0).float()\n",
    "        \n",
    "        return image, onehot_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f51a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.one_hot(torch.tensor([2, 6]), num_classes=20).sum(dim=0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dedb86",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    image = train_image[i]\n",
    "    label = training_labels[i]\n",
    "    \n",
    "    plt.imshow(image)\n",
    "    print(label)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3712a1e0",
   "metadata": {},
   "source": [
    "### 1.4 Transform image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332a0512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transform and argumentation (data preprocessing)\n",
    "\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToTensor(),        \n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecfb7fc",
   "metadata": {},
   "source": [
    "### 1.5 Final Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b27153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final data\n",
    "images_pascal = {\n",
    "    'train' : ImageDataset(training_labels, train_image, labels, data_transforms['train']),\n",
    "    'val': ImageDataset(validation_labels, val_image, labels, data_transforms['val']),\n",
    "    'test': ImageDataset(test_labels, total_test_image, labels, data_transforms['test'])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11155816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot image in Pytorch\n",
    "image, label = (images_pascal['train'])[15]\n",
    "image = image.permute(1, 2, 0)\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522fb047",
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e5a904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "dataloaders = {\n",
    "    'train': DataLoader(images_pascal['train'], batch_size=16, shuffle=True),\n",
    "    'val': DataLoader(images_pascal['val'], batch_size=16, shuffle=False),\n",
    "    'test': DataLoader(images_pascal['test'], batch_size=16, shuffle=False)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa33077",
   "metadata": {},
   "source": [
    "## 2. CNN structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4aa3a2",
   "metadata": {},
   "source": [
    "- In this part I will be test 3 CNN structure include ResNet50, ResNet18,  as a backbone to extract feature of input image\n",
    "- The last layer will be a fully connected layer with number of out-put node equal to the number of classes and using `Sigmoid activation`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f2ab83",
   "metadata": {},
   "source": [
    "## 2.1. ResNet18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b5449a",
   "metadata": {},
   "source": [
    "## 2.2 ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ff10b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load a pretrained model and reset the final fully connected layers\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "## FIne tuning the convnet: Instead of random initialization, we initialize the network with a pretrained network\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, model, num_classes):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        #Finetuning the convnet\n",
    "        in_ftrs = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(in_ftrs, 128)\n",
    "        self.fc_head = nn.Linear(128, self.num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.model(x))\n",
    "        x = torch.sigmoid(self.fc_head(x))\n",
    "        return x\n",
    "\n",
    "model = NeuralNetwork(model, num_classes = len(labels)).to(device)\n",
    "# model = NeuralNetwork(model, num_classes = len(labels))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dc5bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test DataLoader\n",
    "examples = iter(dataloaders['train'])\n",
    "example_images, example_labellists = examples.next()\n",
    "print('Batch image size: ', example_images.shape)\n",
    "print('Batch label size: ', example_labellists.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf34ecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add model graph to Tensorboard\n",
    "writer.add_graph(model, example_images.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009ff46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss function and Optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimize parameter rely on paper Deep Residual Learning for Image Recognition\n",
    "optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "step_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dd429a",
   "metadata": {},
   "source": [
    "# Training and evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daad0236",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {x: len(images_pascal[x]) for x in ['train', 'val']}\n",
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d3035d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scheduling the learning rate\n",
    "# Saving the best model\n",
    "\n",
    "def train_model(model, dataloaders, labels, criterion, optimizer, scheduler, num_epochs, writer):\n",
    "    since = time.time() # start time\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict()) # copy best model\n",
    "    best_acc = 0.0\n",
    "\n",
    "    # loop throught datset\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            # Train info\n",
    "            running_loss = torch.tensor(0.0).to(device)\n",
    "            running_corrects = torch.zeros(len(labels)).to(device)\n",
    "            running_total = torch.zeros(len(labels)).to(device)\n",
    "            # Iterate over data.\n",
    "            for inputs, labellist in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labellist = labellist.to(device)\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                # zero the parameter gradient\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    preds = outputs.round()\n",
    "                    loss = criterion(outputs, labellist)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "#                         optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics the results\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labellist.data, dim=0)\n",
    "                running_total += labellist.size(0)\n",
    "                \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                \n",
    "#             epoch_loss = running_loss / dataset_sizes[phase]\n",
    "#             epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            epoch_loss = running_loss / running_total.sum()\n",
    "            epoch_cls_acc = running_corrects.double() / running_total * 100\n",
    "            epoch_acc = epoch_cls_acc.mean()\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            # Tensorboard\n",
    "            writer.add_scalar(\"{}/loss\".format(phase), epoch_loss, epoch)\n",
    "            writer.add_scalar(\"{}/accuracy/average\".format(phase), epoch_acc, epoch)\n",
    "            \n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d626ad97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = train_model(model, dataloaders, labels, criterion, optimizer_ft, step_lr_scheduler, 25, writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1d7eba",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e563a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "since = time.time()\n",
    "\n",
    "# Convert to eval model\n",
    "model.eval()\n",
    "\n",
    "# Train info\n",
    "running_loss = torch.tensor(0.0).to(device)\n",
    "running_corrects = torch.zeros(len(labels)).to(device)\n",
    "running_total = torch.zeros(len(labels)).to(device)\n",
    "\n",
    "\n",
    "for images, labellists in dataloaders['test']:\n",
    "    # To GPU\n",
    "    images = images.to(device)\n",
    "    labellists = labellists.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "        preds = outputs.round()\n",
    "        loss = criterion(outputs, labellists)\n",
    "        \n",
    "    # Statistics\n",
    "    running_loss += loss.item() * images.size(0)\n",
    "    running_corrects += torch.sum(preds == labellists.data, dim=0)\n",
    "    running_total += labellists.size(0)\n",
    "    \n",
    "loss = running_loss / running_total.sum()\n",
    "cls_loss = running_corrects.double() / running_total * 100\n",
    "acc = cls_loss.mean()\n",
    "\n",
    "print('Finish testing after {:.2f}s'.format(time.time() - since))\n",
    "print('Loss: {:.4f} - Acc: {:.2f}%'.format(loss, acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labtest",
   "language": "python",
   "name": "labtest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
