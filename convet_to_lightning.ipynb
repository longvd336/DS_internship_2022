{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36e61668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import math\n",
    "import itertools\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bcb1b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device config\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper params\n",
    "batch_size = 32\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "\n",
    "# Random seed\n",
    "seed = 2022\n",
    "torch.random.manual_seed(seed)\n",
    "np.random.seed(2022)\n",
    "\n",
    "# Tensorboard writer\n",
    "# writer = SummaryWriter(\"runs/multilabelsclass\")\n",
    "\n",
    "# logger\n",
    "logger = TensorBoardLogger('runs', 'lightning')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861c95b3",
   "metadata": {},
   "source": [
    "# Data Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ef0d12",
   "metadata": {},
   "source": [
    "# 1. Read Image & Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0cd2a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory\n",
    "data_dir = '../pascal_2007'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.mkdir(data_dir)\n",
    "    \n",
    "# Save directory\n",
    "save_dir = './saved'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "# Image directory\n",
    "train_img_dir = os.path.join(data_dir, 'train')\n",
    "test_img_dir = os.path.join(data_dir, 'test')\n",
    "\n",
    "# Annotaion file\n",
    "train_anno_file = os.path.join(data_dir, 'train.csv')\n",
    "test_anno_file = os.path.join(data_dir, 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80efab2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create custom dataset:\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    # __init_function run once when instantiating the Dataset object\n",
    "    def __init__(self, annotations, images, labellist, transforms=None):\n",
    "        super().__init__()\n",
    "        self.img = images\n",
    "        self.annotations = annotations    \n",
    "        self.labellist = labellist\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    # __len__ func return the num of samples in dataset \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    # Load and return a sample from the dataset at the given index `idx` then convert it to tensor \n",
    "    # retrieves the corresponding labels from the csv data, call the transform function on them (if applicable)\n",
    "    # then return the tensor image and corresponding label.\n",
    "    \n",
    "    # convert label of and sample to index of these label in the labellist\n",
    "    def text_to_index(self, labellist, annotations):\n",
    "        index = []\n",
    "        for item in annotations:\n",
    "            index.append(self.labellist.index(item))\n",
    "        return index\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # convert image to tensor and transform image\n",
    "        image = self.img[idx]\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "            \n",
    "        # convert label to one hot encoding\n",
    "        labels_index = self.text_to_index(self.labellist, self.annotations[idx])\n",
    "        labels_index = torch.tensor(labels_index)\n",
    "        labels_onehot = F.one_hot(labels_index, num_classes=len(self.labellist))\n",
    "        onehot_label = labels_onehot.sum(dim=0).float()\n",
    "        \n",
    "        return image, onehot_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c3ec9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transform and argumentation (data preprocessing)\n",
    "\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToTensor(),        \n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b613ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PascalDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir, save_dir, transforms, batch_size: 32):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.train_img_dir = os.path.join(self.data_dir, 'train') \n",
    "        self.test_img_dir = os.path.join(self.data_dir, 'test')\n",
    "        self.train_anno_file = os.path.join(self.data_dir, 'train.csv')\n",
    "        self.test_anno_file = os.path.join(self.data_dir, 'test.csv')\n",
    "        self.save_dir = save_dir\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def setup(self, stage: None):\n",
    "        (train_images, training_labels), (val_images, validation_labels) = self.load_train_images_and_labels(self.train_img_dir, self.train_anno_file)\n",
    "        (test_images, test_labels) = self.load_test_images_and_labels(self.test_img_dir, self.test_anno_file)\n",
    "        \n",
    "        # labels\n",
    "        self.labels = self.get_labels(training_labels)\n",
    "        \n",
    "        self.images_pascal = {\n",
    "        'train' : ImageDataset(training_labels, train_images, self.labels, data_transforms['train']),\n",
    "        'val': ImageDataset(validation_labels, val_images, self.labels, data_transforms['val']),\n",
    "        'test': ImageDataset(test_labels, test_images, self.labels, data_transforms['test'])\n",
    "        }\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.images_pascal['train'], batch_size=16, shuffle=True)\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.images_pascal['val'], batch_size=16, shuffle=False)\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.images_pascal['test'], batch_size=16, shuffle=False)\n",
    "    \n",
    "    def get_labels(self, training_labels):\n",
    "        # Get all labels\n",
    "        labels = []\n",
    "\n",
    "        for label in training_labels:\n",
    "            labels = labels + label\n",
    "\n",
    "        labels = sorted(list(set(labels)))\n",
    "\n",
    "        print('Number of labels: ', len(labels))\n",
    "        return labels\n",
    "    \n",
    "    def convert_label_to_array(self, labels):\n",
    "        for ind, label in enumerate(labels):\n",
    "            labels[ind] = label.split(\" \")\n",
    "        return labels    \n",
    "\n",
    "    def load_train_images_and_labels(self, image_dir, anno_path):\n",
    "        train_label = pd.read_csv(anno_path)\n",
    "        train_image_label_value = (train_label[\"is_valid\"].values)\n",
    "        \n",
    "        # get all index of training image and validation image\n",
    "        train_image_label_index = [i for i, x in enumerate(train_image_label_value) if x]\n",
    "        valid_image_label_index = [i for i, x in enumerate(train_image_label_value) if not x]\n",
    "        \n",
    "        ## get all image file\n",
    "        image_file_name = train_label[\"fname\"].values\n",
    "        \n",
    "        # Read all training image\n",
    "        total_train_image = [] \n",
    "        for image in image_file_name:\n",
    "            image = plt.imread(os.path.join(image_dir, image))\n",
    "            total_train_image.append(image)\n",
    "        \n",
    "        train_images = [ total_train_image[i] for i in train_image_label_index]\n",
    "        val_images = [ total_train_image[i] for i in valid_image_label_index]\n",
    "        \n",
    "        ## Read all label for train and val data\n",
    "        labels = train_label[\"labels\"].values\n",
    "\n",
    "        training_labels = labels[train_image_label_index]\n",
    "        validation_labels = labels[valid_image_label_index]\n",
    "        \n",
    "        training_labels = self.convert_label_to_array(training_labels)\n",
    "        validation_labels = self.convert_label_to_array(validation_labels)\n",
    "        \n",
    "        return (train_images, training_labels), (val_images, validation_labels)\n",
    "   \n",
    "    def load_test_images_and_labels(self, image_dir, anno_path):\n",
    "        ## get all image file\n",
    "        test_label = pd.read_csv(anno_path)\n",
    "        test_image_file_name = test_label[\"fname\"].values\n",
    "        \n",
    "        ## Test data\n",
    "        test_images = [] \n",
    "        for image in test_image_file_name:\n",
    "            image = plt.imread(os.path.join(image_dir, image))\n",
    "            test_images.append(image)\n",
    "\n",
    "        test_labels = test_label[\"labels\"].values\n",
    "        test_labels = self.convert_label_to_array(test_labels)\n",
    "        \n",
    "        return (test_images, test_labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f2fe0202",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = PascalDataModule(data_dir, save_dir, transforms, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9366ef",
   "metadata": {},
   "source": [
    "## Lightning Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f2b12f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/longvuduc/DS_internship_2022/labtest/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/longvuduc/DS_internship_2022/labtest/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "## Load a pretrained model and reset the final fully connected layers\n",
    "## FIne tuning the convnet: Instead of random initialization, we initialize the network with a pretrained network\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, model, num_classes):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        #Finetuning the convnet\n",
    "        in_ftrs = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(in_ftrs, 128)\n",
    "        self.fc_head = nn.Linear(128, self.num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.model(x))\n",
    "        x = torch.sigmoid(self.fc_head(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0c6fafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitModel(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                num_classes,\n",
    "                model,\n",
    "                learning_rate=0.01,\n",
    "                momentum=0.9,\n",
    "                step_size=5,\n",
    "                gamma=0.5):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.model = NeuralNetwork(model, num_classes)\n",
    "        \n",
    "        # Hyper parameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.criterion = nn.BCELoss()\n",
    "        self.momentum = momentum\n",
    "        self.lr_schedule_step = step_size\n",
    "        self.lr_schedule_factor = gamma\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        \n",
    "        preds = y_hat.round()\n",
    "        num_corrects = torch.sum(preds == y.data, dim=0)\n",
    "        cls_accuracy = num_corrects / y.size(0)\n",
    "        avg_accuracy = cls_accuracy.mean() * 100\n",
    "        \n",
    "        tensorboard_log = {'acc': avg_accuracy}\n",
    "        \n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'log': tensorboard_log\n",
    "        }\n",
    "    \n",
    "        # Config callbacks\n",
    "    def configure_callbacks(self):\n",
    "        return [\n",
    "            EarlyStopping(monitor='val/accuracy', mode='max', verbose=1, patience=10), \n",
    "            ModelCheckpoint(os.path.join(save_dir, 'checkpoints'), monitor='val/accuracy', mode='max', save_weights_only=True, verbose=1)\n",
    "        ]\n",
    "    \n",
    "    def configure_optimizers(self, ):\n",
    "        optimizer = optim.SGD(self.parameters(), lr=self.learning_rate, momentum=self.momentum)\n",
    "        lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=self.lr_schedule_step, gamma=self.lr_schedule_factor)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "\n",
    "        preds = y_hat.round()\n",
    "        num_corrects = torch.sum(preds == y.data, dim=0)\n",
    "        cls_accuracy = num_corrects / y.size(0)\n",
    "        avg_accuracy = cls_accuracy.mean() * 100\n",
    "        \n",
    "        tensorboard_log = {'acc': avg_accuracy}\n",
    "        \n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'log': tensorboard_log\n",
    "        }\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "\n",
    "        preds = y_hat.round()\n",
    "        num_corrects = torch.sum(preds == y.data, dim=0)\n",
    "        cls_accuracy = num_corrects / y.size(0)\n",
    "        avg_accuracy = cls_accuracy.mean() * 100\n",
    "        \n",
    "        tensorboard_log = {'acc': avg_accuracy}\n",
    "        \n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'log': tensorboard_log\n",
    "        }\n",
    "    \n",
    "    def state_dict(self):\n",
    "        return self.model.state_dict()\n",
    "    \n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.model.load_state_dict(state_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa772355",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitModel(\n",
    "    num_classes=20,\n",
    "    model=model,\n",
    "    learning_rate=learning_rate,\n",
    "    momentum=momentum\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9652e3b6",
   "metadata": {},
   "source": [
    "## Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "542768d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging Callback\n",
    "class MyLoggingCallback(pl.callbacks.Callback):\n",
    "    def __init__(self, every_batch=100):\n",
    "        super().__init__()\n",
    "        self.every_batch = every_batch\n",
    "\n",
    "    # Train\n",
    "    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, unused=0): \n",
    "        # Calculate and log batch accuracy\n",
    "        self.log('train/loss', outputs['loss'])\n",
    "        self.log('train/accuracy', outputs['log']['acc'])\n",
    "    \n",
    "    # Valid \n",
    "    def on_validation_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, unused=0): \n",
    "        # Calculate and log batch accuracy\n",
    "        self.log('val/loss', outputs['loss'])\n",
    "        self.log('val/accuracy', outputs['log']['acc'])\n",
    "        \n",
    "    # Test\n",
    "    def on_test_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, unused=0): \n",
    "        # Calculate and log batch accuracy\n",
    "        self.log('test/loss', outputs['loss'])\n",
    "        self.log('test/accuracy', outputs['log']['acc'])\n",
    "        \n",
    "## Visualization Callback \n",
    "\n",
    "class VisualizationCallback(pl.callbacks.Callback):\n",
    "    def get_kernel_weight(self, pl_module):\n",
    "        # get the first kernel weight\n",
    "        kernel = pl_module.model.model.conv1.weight.detach().cpu()\n",
    "        \n",
    "        # scale the kernel\n",
    "        kernels = (kernels - kernels.min()) / kernels.max()\n",
    "        filters = torchvision.utils.make_grid(kernels.clamp(0, 1))\n",
    "        return filters\n",
    "    \n",
    "    def visualize_kernel(self, trainer, pl_module, stage=None):\n",
    "        if stage=='fit':\n",
    "            pl_module.logger.experiment.add_image('filters', self.get_kernels(pl_module))\n",
    "                \n",
    "            sampleImg=torch.rand((32, 3, 224, 224))\n",
    "            pl_module.logger.experiment.add_graph(pl_module.model,sampleImg)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a3b900",
   "metadata": {},
   "source": [
    "## Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a31473c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/longvuduc/DS_internship_2022/labtest/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:447: LightningDeprecationWarning: Setting `Trainer(gpus=[0])` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=[0])` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: ModelCheckpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels:  20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name      | Type          | Params\n",
      "--------------------------------------------\n",
      "0 | model     | NeuralNetwork | 23.8 M\n",
      "1 | criterion | BCELoss       | 0     \n",
      "--------------------------------------------\n",
      "23.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.8 M    Total params\n",
      "95.092    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/longvuduc/DS_internship_2022/labtest/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/longvuduc/DS_internship_2022/labtest/lib/python3.8/site-packages/torchvision/transforms/functional.py:150: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:172.)\n",
      "  img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n",
      "/home/longvuduc/DS_internship_2022/labtest/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e28a1297baa4e98994e40431455969e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/accuracy improved. New best score: 91.967\n",
      "Epoch 0, global step 157: 'val/accuracy' reached 91.96722 (best 91.96722), saving model to '/home/longvuduc/DS_internship_2022/mul_class_classification/saved/checkpoints/epoch=0-step=157.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/accuracy improved by 0.002 >= min_delta = 0.0. New best score: 91.969\n",
      "Epoch 1, global step 314: 'val/accuracy' reached 91.96922 (best 91.96922), saving model to '/home/longvuduc/DS_internship_2022/mul_class_classification/saved/checkpoints/epoch=1-step=314.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/accuracy improved by 0.134 >= min_delta = 0.0. New best score: 92.103\n",
      "Epoch 2, global step 471: 'val/accuracy' reached 92.10316 (best 92.10316), saving model to '/home/longvuduc/DS_internship_2022/mul_class_classification/saved/checkpoints/epoch=2-step=471.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/accuracy improved by 0.404 >= min_delta = 0.0. New best score: 92.507\n",
      "Epoch 3, global step 628: 'val/accuracy' reached 92.50700 (best 92.50700), saving model to '/home/longvuduc/DS_internship_2022/mul_class_classification/saved/checkpoints/epoch=3-step=628.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/accuracy improved by 0.406 >= min_delta = 0.0. New best score: 92.913\n",
      "Epoch 4, global step 785: 'val/accuracy' reached 92.91283 (best 92.91283), saving model to '/home/longvuduc/DS_internship_2022/mul_class_classification/saved/checkpoints/epoch=4-step=785.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/accuracy improved by 0.112 >= min_delta = 0.0. New best score: 93.025\n",
      "Epoch 5, global step 942: 'val/accuracy' reached 93.02479 (best 93.02479), saving model to '/home/longvuduc/DS_internship_2022/mul_class_classification/saved/checkpoints/epoch=5-step=942.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/accuracy improved by 0.100 >= min_delta = 0.0. New best score: 93.125\n",
      "Epoch 6, global step 1099: 'val/accuracy' reached 93.12475 (best 93.12475), saving model to '/home/longvuduc/DS_internship_2022/mul_class_classification/saved/checkpoints/epoch=6-step=1099.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/accuracy improved by 0.074 >= min_delta = 0.0. New best score: 93.199\n",
      "Epoch 7, global step 1256: 'val/accuracy' reached 93.19872 (best 93.19872), saving model to '/home/longvuduc/DS_internship_2022/mul_class_classification/saved/checkpoints/epoch=7-step=1256.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/accuracy improved by 0.012 >= min_delta = 0.0. New best score: 93.211\n",
      "Epoch 8, global step 1413: 'val/accuracy' reached 93.21072 (best 93.21072), saving model to '/home/longvuduc/DS_internship_2022/mul_class_classification/saved/checkpoints/epoch=8-step=1413.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/accuracy improved by 0.012 >= min_delta = 0.0. New best score: 93.223\n",
      "Epoch 9, global step 1570: 'val/accuracy' reached 93.22271 (best 93.22271), saving model to '/home/longvuduc/DS_internship_2022/mul_class_classification/saved/checkpoints/epoch=9-step=1570.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/accuracy improved by 0.246 >= min_delta = 0.0. New best score: 93.469\n",
      "Epoch 10, global step 1727: 'val/accuracy' reached 93.46861 (best 93.46861), saving model to '/home/longvuduc/DS_internship_2022/mul_class_classification/saved/checkpoints/epoch=10-step=1727.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 1884: 'val/accuracy' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/accuracy improved by 0.040 >= min_delta = 0.0. New best score: 93.509\n",
      "Epoch 12, global step 2041: 'val/accuracy' reached 93.50860 (best 93.50860), saving model to '/home/longvuduc/DS_internship_2022/mul_class_classification/saved/checkpoints/epoch=12-step=2041.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/accuracy improved by 0.026 >= min_delta = 0.0. New best score: 93.535\n",
      "Epoch 13, global step 2198: 'val/accuracy' reached 93.53458 (best 93.53458), saving model to '/home/longvuduc/DS_internship_2022/mul_class_classification/saved/checkpoints/epoch=13-step=2198.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/accuracy improved by 0.050 >= min_delta = 0.0. New best score: 93.585\n",
      "Epoch 14, global step 2355: 'val/accuracy' reached 93.58456 (best 93.58456), saving model to '/home/longvuduc/DS_internship_2022/mul_class_classification/saved/checkpoints/epoch=14-step=2355.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/accuracy improved by 0.072 >= min_delta = 0.0. New best score: 93.657\n",
      "Epoch 15, global step 2512: 'val/accuracy' reached 93.65654 (best 93.65654), saving model to '/home/longvuduc/DS_internship_2022/mul_class_classification/saved/checkpoints/epoch=15-step=2512.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 2669: 'val/accuracy' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/accuracy improved by 0.150 >= min_delta = 0.0. New best score: 93.806\n",
      "Epoch 17, global step 2826: 'val/accuracy' reached 93.80648 (best 93.80648), saving model to '/home/longvuduc/DS_internship_2022/mul_class_classification/saved/checkpoints/epoch=17-step=2826.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, global step 2983: 'val/accuracy' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 3140: 'val/accuracy' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20, global step 3297: 'val/accuracy' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21, global step 3454: 'val/accuracy' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/accuracy improved by 0.048 >= min_delta = 0.0. New best score: 93.854\n",
      "Epoch 22, global step 3611: 'val/accuracy' reached 93.85446 (best 93.85446), saving model to '/home/longvuduc/DS_internship_2022/mul_class_classification/saved/checkpoints/epoch=22-step=3611.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/accuracy improved by 0.010 >= min_delta = 0.0. New best score: 93.864\n",
      "Epoch 23, global step 3768: 'val/accuracy' reached 93.86446 (best 93.86446), saving model to '/home/longvuduc/DS_internship_2022/mul_class_classification/saved/checkpoints/epoch=23-step=3768.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24, global step 3925: 'val/accuracy' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25, global step 4082: 'val/accuracy' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26, global step 4239: 'val/accuracy' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27, global step 4396: 'val/accuracy' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28, global step 4553: 'val/accuracy' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, global step 4710: 'val/accuracy' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30, global step 4867: 'val/accuracy' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/accuracy improved by 0.012 >= min_delta = 0.0. New best score: 93.876\n",
      "Epoch 31, global step 5024: 'val/accuracy' reached 93.87645 (best 93.87645), saving model to '/home/longvuduc/DS_internship_2022/mul_class_classification/saved/checkpoints/epoch=31-step=5024.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/accuracy improved by 0.016 >= min_delta = 0.0. New best score: 93.892\n",
      "Epoch 32, global step 5181: 'val/accuracy' reached 93.89244 (best 93.89244), saving model to '/home/longvuduc/DS_internship_2022/mul_class_classification/saved/checkpoints/epoch=32-step=5181.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33, global step 5338: 'val/accuracy' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34, global step 5495: 'val/accuracy' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35, global step 5652: 'val/accuracy' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/accuracy improved by 0.002 >= min_delta = 0.0. New best score: 93.894\n",
      "Epoch 36, global step 5809: 'val/accuracy' reached 93.89444 (best 93.89444), saving model to '/home/longvuduc/DS_internship_2022/mul_class_classification/saved/checkpoints/epoch=36-step=5809.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37, global step 5966: 'val/accuracy' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38, global step 6123: 'val/accuracy' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39, global step 6280: 'val/accuracy' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40, global step 6437: 'val/accuracy' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41, global step 6594: 'val/accuracy' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42, global step 6751: 'val/accuracy' was not in top 1\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    gpus=[0],\n",
    "    max_epochs=num_epochs,\n",
    "    logger=logger,\n",
    "    fast_dev_run=False,\n",
    "    log_every_n_steps=1,\n",
    "    callbacks=[MyLoggingCallback(), VisualizationCallback()]\n",
    ")\n",
    "\n",
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531144d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model, data_module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labtest",
   "language": "python",
   "name": "labtest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
